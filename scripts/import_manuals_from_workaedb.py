"""
–ò–º–ø–æ—Ä—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏–∑ work-aedb –≤ norake-backend Document Services.

–°–∫—Ä–∏–ø—Ç —á–∏—Ç–∞–µ—Ç JSON —Ñ–∞–π–ª—ã –∏–∑ work-aedb (categories, groups, manuals),
—Å–∫–∞—á–∏–≤–∞–µ—Ç PDF —Å Yandex Cloud –∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏—Ö –≤ Document Services
—Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –º–∞–ø–ø–∏–Ω–≥–æ–º –¥–∞–Ω–Ω—ã—Ö, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ç–µ–≥–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ–±–ª–æ–∂–µ–∫.

Usage:
    python scripts/import_manuals_from_workaedb.py [--workaedb-path ../work-aedb]

Requirements:
    - work-aedb –ø—Ä–æ–µ–∫—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Å–æ—Å–µ–¥–Ω–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–∏–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å)
    - JSON —Ñ–∞–π–ª—ã: app/data/manuals/{categories,groups,manuals}.json
    - norake-backend –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ë–î
    - S3 credentials –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –≤ .env
    - Poppler —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±–ª–æ–∂–µ–∫ (—Å–º. docs/POPPLER_SETUP.md)
      * Windows: choco install poppler
      * Linux: sudo apt-get install poppler-utils
      * macOS: brew install poppler

Features:
    ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ PDF –∏–∑ Yandex Cloud
    ‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è thumbnail (–æ–±–ª–æ–∂–µ–∫) –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF
    ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ (—Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞, —è–∑—ã–∫, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å, —Å–µ—Ä–∏—è)
    ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏–π —Å –≤–µ—Ä—Å–∏–µ–π –∏ –¥–∞—Ç–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞
    ‚úÖ –ü—É–±–ª–∏—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (is_public=True) –¥–ª—è –æ–±—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞
"""

import asyncio
import io
import json
import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional

import httpx
from fastapi import UploadFile
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.connections.database import DatabaseClient
from src.core.connections.storage import S3ContextManager
from src.core.integrations.storages.documents import DocumentS3Storage
from src.core.settings.base import settings
from src.models.v1.document_services import CoverType, DocumentFileType
from src.models.v1.users import UserModel
from src.models.v1.workspaces import WorkspaceModel
from src.services.v1.document_services import DocumentServiceService

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class ManualImporter:
    """
    –ò–º–ø–æ—Ä—Ç—ë—Ä –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏–∑ work-aedb –≤ Document Services.

    Workflow:
        1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON (categories, groups, manuals) –∏–∑ work-aedb
        2. –°–∫–∞—á–∏–≤–∞–µ—Ç PDF —Å Yandex Cloud —á–µ—Ä–µ–∑ httpx
        3. –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –≤ S3 norake-backend (–ø–∞–ø–∫–∞ documents/)
        4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç thumbnail –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF (–ø–∞–ø–∫–∞ thumbnails/)
        5. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–≥–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è (–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ/–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è/–ë—Ä–æ—à—É—Ä–∞ + —è–∑—ã–∫)
        6. –°–æ–∑–¥–∞—ë—Ç Document Service —á–µ—Ä–µ–∑ DocumentServiceService

    Cover Generation:
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç pdf2image + poppler –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF ‚Üí JPEG
        - –†–∞–∑–º–µ—Ä: 400x566px, –∫–∞—á–µ—Å—Ç–≤–æ 85%
        - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ S3: thumbnails/public/{uuid}_filename_thumbnail.jpg
        - –ï—Å–ª–∏ poppler –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Üí warning, –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–µ—Ç—Å—è –±–µ–∑ –æ–±–ª–æ–∂–∫–∏
    """

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —è–∑—ã–∫–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏–π
    DOCUMENT_TYPES = {
        "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ": "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ",
        "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è": "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è",
        "–±—Ä–æ—à—É—Ä–∞": "–±—Ä–æ—à—É—Ä–∞",
        "–∫–∞—Ç–∞–ª–æ–≥": "–∫–∞—Ç–∞–ª–æ–≥",
        "–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ": "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã",
        "manual": "manual",
        "guide": "guide",
        "datasheet": "datasheet",
        "user guide": "user guide",
        "quick": "quick start",
        "–∫—Ä–∞—Ç–∫–æ–µ": "–∫—Ä–∞—Ç–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ",
    }

    LANGUAGES = {
        "ru": "—Ä—É—Å—Å–∫–∏–π",
        "en": "english",
        "cn": "chinese",
        "ch": "chinese",
    }

    def __init__(self, workaedb_path: str = "../work-aedb"):
        """
        Args:
            workaedb_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ work-aedb –ø—Ä–æ–µ–∫—Ç–∞.
        """
        self.workaedb_path = Path(workaedb_path)
        self.data_path = self.workaedb_path / "app" / "data" / "manuals"

        self.categories: List[Dict] = []
        self.groups: List[Dict] = []
        self.manuals: List[Dict] = []

        self.category_map: Dict[int, str] = {}  # id ‚Üí name
        self.group_map: Dict[int, Dict] = {}  # id ‚Üí {name, category_id}

        self.http_client: Optional[httpx.AsyncClient] = None
        self.s3_context: Optional[S3ContextManager] = None
        self.s3_client: Optional[Any] = None
        self.storage: Optional[DocumentS3Storage] = None
        self.session: Optional[AsyncSession] = None
        self.service: Optional[DocumentServiceService] = None

        self.default_user: Optional[UserModel] = None
        self.default_workspace: Optional[WorkspaceModel] = None

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "total": 0,
            "success": 0,
            "skipped": 0,
            "errors": [],
        }

    async def __aenter__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è async —Ä–µ—Å—É—Ä—Å–æ–≤."""
        self.http_client = httpx.AsyncClient(timeout=300.0)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è S3 —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä (–∫–∞–∫ –≤ –ø—Ä–æ–µ–∫—Ç–µ)
        self.s3_context = S3ContextManager()
        self.s3_client = await self.s3_context.__aenter__()
        self.storage = DocumentS3Storage(s3_client=self.s3_client)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î —á–µ—Ä–µ–∑ DatabaseClient (singleton)
        db_client = await DatabaseClient.get_instance()
        session_factory = await db_client.connect()
        self.session = session_factory()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞
        self.service = DocumentServiceService(
            session=self.session,
            s3_client=self.s3_client,
            settings=settings,
        )

        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ workspace
        await self._get_default_user_and_workspace()

        logger.info("ManualImporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ async —Ä–µ—Å—É—Ä—Å–æ–≤."""
        if self.http_client:
            await self.http_client.aclose()
        if self.s3_context:
            await self.s3_context.__aexit__(exc_type, exc_val, exc_tb)
        if self.session:
            await self.session.close()
        logger.info("ManualImporter –∑–∞–∫—Ä—ã—Ç")

    async def _get_default_user_and_workspace(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ workspace –¥–ª—è author_id."""
        from sqlalchemy import select

        # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        result = await self.session.execute(select(UserModel).limit(1))
        self.default_user = result.scalar_one_or_none()

        if not self.default_user:
            raise ValueError(
                "–í –ë–î –Ω–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π! –°–æ–∑–¥–∞–π—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ —Ñ–∏–∫—Å—Ç—É—Ä—ã –∏–ª–∏ API."
            )

        # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π workspace (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        result = await self.session.execute(select(WorkspaceModel).limit(1))
        self.default_workspace = result.scalar_one_or_none()

        logger.info(
            "–î–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: %s (id=%s)",
            self.default_user.username,
            self.default_user.id,
        )
        if self.default_workspace:
            logger.info(
                "–î–µ—Ñ–æ–ª—Ç–Ω—ã–π workspace: %s (id=%s)",
                self.default_workspace.name,
                self.default_workspace.id,
            )

    def load_json_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON —Ñ–∞–π–ª—ã –∏–∑ work-aedb."""
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ JSON —Ñ–∞–π–ª–æ–≤ –∏–∑ %s", self.data_path)

        categories_file = self.data_path / "categories.json"
        groups_file = self.data_path / "groups.json"
        manuals_file = self.data_path / "manuals.json"

        with open(categories_file, "r", encoding="utf-8") as f:
            self.categories = json.load(f)

        with open(groups_file, "r", encoding="utf-8") as f:
            self.groups = json.load(f)

        with open(manuals_file, "r", encoding="utf-8") as f:
            self.manuals = json.load(f)

        # –°–æ–∑–¥–∞—ë–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        for idx, category in enumerate(self.categories, start=1):
            self.category_map[idx] = category["name"]

        for idx, group in enumerate(self.groups, start=1):
            self.group_map[idx] = {
                "name": group["name"],
                "category_id": group["category_id"],
            }

        logger.info(
            "–ó–∞–≥—Ä—É–∂–µ–Ω–æ: %d –∫–∞—Ç–µ–≥–æ—Ä–∏–π, %d –≥—Ä—É–ø–ø, %d –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π",
            len(self.categories),
            len(self.groups),
            len(self.manuals),
        )

    async def download_file(self, url: str) -> bytes:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å Yandex Cloud —á–µ—Ä–µ–∑ HTTP.

        Args:
            url: Yandex Cloud URL (https://storage.yandexcloud.net/...)

        Returns:
            bytes: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞.

        Raises:
            httpx.HTTPError: –ü—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏.
        """
        logger.debug("–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞: %s", url)
        response = await self.http_client.get(url)
        response.raise_for_status()
        return response.content

    def extract_tags(self, manual_name: str, category: str, group: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–≥–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.

        –¢–µ–≥–∏:
        - –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ/–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è/–±—Ä–æ—à—É—Ä–∞/manual/guide)
        - –Ø–∑—ã–∫ (Ru/En/Cn)
        - –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å (–∫–∞—Ç–µ–≥–æ—Ä–∏—è)
        - –°–µ—Ä–∏—è (–≥—Ä—É–ø–ø–∞)

        Args:
            manual_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ JSON.
            category: –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å.
            group: –°–µ—Ä–∏—è.

        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤.

        Example:
            >>> extract_tags(
            ...     "ASC800 –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –º–∏–∫—Ä–æ–ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–º—É –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—é 1209 Ru",
            ...     "ABB (–®–≤–µ–π—Ü–∞—Ä–∏—è)",
            ...     "ASC"
            ... )
            ['—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ', '—Ä—É—Å—Å–∫–∏–π', 'abb', 'asc', '–º–∏–∫—Ä–æ–ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ']
        """
        tags = set()
        name_lower = manual_name.lower()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞
        for pattern, tag in self.DOCUMENT_TYPES.items():
            if pattern in name_lower:
                tags.add(tag)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —è–∑—ã–∫
        for pattern, lang in self.LANGUAGES.items():
            if f" {pattern}" in name_lower or name_lower.endswith(pattern):
                tags.add(lang)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è (–±–µ–∑ —Å—Ç—Ä–∞–Ω—ã)
        category_clean = re.sub(r"\s*\([^)]*\)", "", category).strip().lower()
        tags.add(category_clean)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ—Ä–∏—é
        tags.add(group.lower())

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ keywords –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if "–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ" in name_lower or "parameter" in name_lower:
            tags.add("–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
        if "—ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è" in name_lower or "operation" in name_lower:
            tags.add("—ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è")
        if "quick" in name_lower or "–∫—Ä–∞—Ç–∫–æ–µ" in name_lower:
            tags.add("quick start")

        return sorted(list(tags))

    def create_description(
        self, manual_name: str, category: str, group: str
    ) -> str:
        """
        –°–æ–∑–¥–∞—ë—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è Document Service.

        Description —Å–æ–¥–µ—Ä–∂–∏—Ç:
        - –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å
        - –°–µ—Ä–∏—è
        - –î–∞—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å 4 —Ü–∏—Ñ—Ä—ã - –º–µ—Å—è—Ü/–≥–æ–¥: MMYY –∏–ª–∏ YYMM)
        - –í–µ—Ä—Å–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å –±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ: v1.0, R01, A00, etc.)

        Args:
            manual_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.
            category: –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å.
            group: –°–µ—Ä–∏—è.

        Returns:
            str: –û–ø–∏—Å–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

        Example:
            >>> create_description(
            ...     "ASC800 –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –º–∏–∫—Ä–æ–ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–º—É –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—é 1209 Ru",
            ...     "ABB (–®–≤–µ–π—Ü–∞—Ä–∏—è)",
            ...     "ASC"
            ... )
            '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å: ABB (–®–≤–µ–π—Ü–∞—Ä–∏—è), –°–µ—Ä–∏—è: ASC, –î–∞—Ç–∞: 12/2009'

            >>> create_description(
            ...     "19011080_A01 MD880-30 Hardware User Guide 202011 Ru",
            ...     "Inovance (–ö–∏—Ç–∞–π)",
            ...     "MD880-30"
            ... )
            '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å: Inovance (–ö–∏—Ç–∞–π), –°–µ—Ä–∏—è: MD880-30, –í–µ—Ä—Å–∏—è: A01, –î–∞—Ç–∞: 11/2020'
        """
        parts = [f"–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å: {category}", f"–°–µ—Ä–∏—è: {group}"]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä—Å–∏—é (–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤–∞—è: A00, B02, v1.0, Rev 06, R01, etc.)
        version_match = re.search(
            r"\b([A-Z]\d{2,}|v\d+\.\d+|Rev\s*\d+|R\d+|SC[Y]?[-_][A-Z]\d+)\b",
            manual_name,
            re.I
        )
        if version_match:
            parts.append(f"–í–µ—Ä—Å–∏—è: {version_match.group(1)}")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É (4 —Ü–∏—Ñ—Ä—ã: MMYY, YYMM –∏–ª–∏ 6 —Ü–∏—Ñ—Ä: YYYYMM, YYMMDD)
        date_match = re.search(r"\b(\d{4}|\d{6})\b", manual_name)
        if date_match:
            date_str = date_match.group(1)
            if len(date_str) == 4:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç (MMYY –∏–ª–∏ YYMM –ø–æ –ª–æ–≥–∏–∫–µ)
                # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–µ 2 —Ü–∏—Ñ—Ä—ã > 12, —Ç–æ —ç—Ç–æ –≥–æ–¥ (YYMM)
                first_two = int(date_str[:2])
                if first_two > 12:
                    # YYMM —Ñ–æ—Ä–º–∞—Ç
                    year = date_str[:2]
                    month = date_str[2:]
                    parts.append(f"–î–∞—Ç–∞: {month}/20{year}")
                else:
                    # MMYY —Ñ–æ—Ä–º–∞—Ç (–∏–ª–∏ YYMM –µ—Å–ª–∏ year < 12)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ç–æ—Ä—ã–µ 2 —Ü–∏—Ñ—Ä—ã
                    last_two = int(date_str[2:])
                    if last_two > 25:  # –í–µ—Ä–æ—è—Ç–Ω–æ —Å—Ç–∞—Ä—ã–π –≥–æ–¥ (19XX)
                        parts.append(f"–î–∞—Ç–∞: {date_str[:2]}/19{date_str[2:]}")
                    else:
                        parts.append(f"–î–∞—Ç–∞: {date_str[:2]}/20{date_str[2:]}")
            elif len(date_str) == 6:
                # YYYYMM –∏–ª–∏ YYMMDD
                if int(date_str[:4]) > 1990:  # YYYYMM —Ñ–æ—Ä–º–∞—Ç
                    parts.append(f"–î–∞—Ç–∞: {date_str[4:]}/{date_str[:4]}")
                else:  # YYMMDD —Ñ–æ—Ä–º–∞—Ç
                    parts.append(f"–î–∞—Ç–∞: {date_str[2:4]}/20{date_str[:2]}")

        return ", ".join(parts)

    async def import_manuals(self):
        """
        –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤ Document Services.

        Workflow –¥–ª—è –∫–∞–∂–¥–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
        1. –°–∫–∞—á–∏–≤–∞–µ—Ç PDF —Å Yandex Cloud
        2. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤ S3 norake-backend
        3. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–≥–∏ –∏ —Å–æ–∑–¥–∞—ë—Ç description
        4. –°–æ–∑–¥–∞—ë—Ç Document Service —á–µ—Ä–µ–∑ service.create_document()
        """
        self.stats["total"] = len(self.manuals)
        logger.info("–ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ %d –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π", self.stats["total"])

        for idx, manual_data in enumerate(self.manuals, start=1):
            manual_name = manual_data["name"]
            yandex_url = manual_data["file_url"]
            group_id = manual_data["group_id"]

            logger.info("[%d/%d] –ò–º–ø–æ—Ä—Ç: %s", idx, self.stats["total"], manual_name)

            try:
                # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ –≥—Ä—É–ø–ø—É
                group_info = self.group_map.get(group_id)
                if not group_info:
                    logger.warning("–ì—Ä—É–ø–ø–∞ group_id=%d –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫", group_id)
                    self.stats["skipped"] += 1
                    continue

                group_name = group_info["name"]
                category_id = group_info["category_id"]
                category_name = self.category_map.get(category_id, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")

                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
                file_content = await self.download_file(yandex_url)

                # –°–æ–∑–¥–∞—ë–º UploadFile –∏–∑ bytes (–∫–∞–∫ –µ—Å–ª–∏ –±—ã —Å —Ñ—Ä–æ–Ω—Ç–∞ –ø—Ä–∏–ª–µ—Ç–µ–ª–æ)
                filename = Path(yandex_url).name
                file_obj = io.BytesIO(file_content)
                upload_file = UploadFile(
                    file=file_obj,
                    filename=filename,
                    size=len(file_content),
                    headers={"content-type": "application/pdf"},
                )

                # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ—Ä–µ–∑ DocumentS3Storage (—Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç file_content)
                file_url, unique_filename, file_size, uploaded_content = await self.storage.upload_document(
                    file=upload_file,
                    workspace_id=None,  # –ü—É–±–ª–∏—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
                )

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º thumbnail (–æ–±–ª–æ–∂–∫–∞) –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º uploaded_content –≤–º–µ—Å—Ç–æ file_content –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                cover_url = await self.storage.generate_pdf_thumbnail(
                    file_content=uploaded_content,
                    filename=unique_filename,
                    workspace_id=None,  # –ü—É–±–ª–∏—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
                )

                if cover_url:
                    logger.info("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –æ–±–ª–æ–∂–∫–∞: %s", cover_url)
                else:
                    logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±–ª–æ–∂–∫—É –¥–ª—è %s", manual_name)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–≥–∏ –∏ —Å–æ–∑–¥–∞—ë–º description
                tags = self.extract_tags(manual_name, category_name, group_name)
                description = self.create_description(
                    manual_name, category_name, group_name
                )

                # –°–æ–∑–¥–∞—ë–º Document Service –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ repository
                document = await self.service.repository.create_item(
                    {
                        "title": manual_name,
                        "description": description,
                        "tags": tags,
                        "file_url": file_url,
                        "file_size": file_size,
                        "file_type": DocumentFileType.PDF.value,  # .value –¥–ª—è enum
                        "cover_type": CoverType.GENERATED.value,  # .value –¥–ª—è enum
                        "cover_url": cover_url,  # URL —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ thumbnail
                        "cover_icon": None,
                        "available_functions": [
                            {
                                "name": "view_pdf",
                                "enabled": True,
                                "label": "–û—Ç–∫—Ä—ã—Ç—å PDF",
                                "icon": "üìÑ",
                            },
                            {
                                "name": "download",
                                "enabled": True,
                                "label": "–°–∫–∞—á–∞—Ç—å",
                                "icon": "üì•",
                            },
                            {
                                "name": "qr_code",
                                "enabled": True,
                                "label": "QR-–∫–æ–¥",
                                "icon": "üì±",
                            },
                        ],
                        "author_id": self.default_user.id,
                        "workspace_id": self.default_workspace.id
                        if self.default_workspace
                        else None,
                        "is_public": True,  # –ü—É–±–ª–∏—á–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
                        "view_count": 0,
                    }
                )

                await self.session.commit()
                logger.info(
                    "‚úÖ –°–æ–∑–¥–∞–Ω Document Service: %s (id=%s)", manual_name, document.id
                )
                self.stats["success"] += 1

                # –ö–æ–º–º–∏—Ç –∫–∞–∂–¥—ã–µ 10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                if idx % 10 == 0:
                    logger.info("–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–º–º–∏—Ç: %d –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", idx)

            except Exception as error:
                logger.error(
                    "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ '%s': %s", manual_name, str(error)
                )
                self.stats["errors"].append(
                    {"manual": manual_name, "error": str(error)}
                )
                self.stats["skipped"] += 1
                await self.session.rollback()

        logger.info("–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω!")
        logger.info("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        logger.info("  –í—Å–µ–≥–æ: %d", self.stats["total"])
        logger.info("  –£—Å–ø–µ—à–Ω–æ: %d", self.stats["success"])
        logger.info("  –ü—Ä–æ–ø—É—â–µ–Ω–æ: %d", self.stats["skipped"])
        logger.info("  –û—à–∏–±–æ–∫: %d", len(self.stats["errors"]))

        if self.stats["errors"]:
            logger.warning("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–æ–∫:")
            for error_info in self.stats["errors"][:10]:  # –ü–µ—Ä–≤—ã–µ 10
                logger.warning(
                    "  - %s: %s", error_info["manual"], error_info["error"]
                )

    async def run_import(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∏–º–ø–æ—Ä—Ç–∞."""
        self.load_json_data()
        await self.import_manuals()


async def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —Å–∫—Ä–∏–ø—Ç–∞."""
    import argparse

    parser = argparse.ArgumentParser(
        description="–ò–º–ø–æ—Ä—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏–∑ work-aedb –≤ norake-backend Document Services"
    )
    parser.add_argument(
        "--workaedb-path",
        type=str,
        default="../work-aedb",
        help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ work-aedb (default: ../work-aedb)",
    )
    args = parser.parse_args()

    async with ManualImporter(workaedb_path=args.workaedb_path) as importer:
        await importer.run_import()


if __name__ == "__main__":
    asyncio.run(main())
